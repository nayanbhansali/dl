{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORCLCyhex8O_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a dataset (for this example, we'll use the digits dataset)\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=7, algorithm='kd_tree')\n",
        "\n",
        "# Initialize the RBM\n",
        "rbm = BernoulliRBM(n_components=625, learning_rate=0.00001, n_iter=10, verbose=True, random_state=42)\n",
        "\n",
        "# Create a pipeline that first applies RBM and then KNN\n",
        "rbm_features_classifier = Pipeline(steps=[(\"rbm\", rbm), (\"knn\", knn)])\n",
        "\n",
        "# Train the RBM-KNN Pipeline\n",
        "rbm_features_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rbm_features_classifier.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"KNN using RBM features:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate and print the classification score\n",
        "rbm_score = rbm_features_classifier.score(X_test, y_test)\n",
        "print(\"RBM Classification score:\", rbm_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-seWHnS0hF_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist['data'], mnist['target']\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data by scaling it\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the RBM model\n",
        "rbm = BernoulliRBM(n_components=256, learning_rate=0.01, n_iter=5, verbose=1)\n",
        "\n",
        "# Initialize the logistic regression model with increased max_iter and class weights\n",
        "logistic = LogisticRegression(max_iter=200, class_weight='balanced')\n",
        "\n",
        "# Create a pipeline that first extracts features using the RBM and then classifies with logistic regression\n",
        "rbm_pipeline = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
        "\n",
        "# Train the pipeline\n",
        "rbm_pipeline.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rbm_pipeline.predict(X_test_scaled)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Logistic Regression using RBM features:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "rbm_score = rbm_pipeline.score(X_test_scaled, y_test)\n",
        "print(\"RBM Classification score:\", rbm_score)\n",
        "\n",
        "# Check the distribution of classes\n",
        "print(\"Training set class distribution:\\n\", pd.Series(y_train).value_counts())\n",
        "print(\"Test set class distribution:\\n\", pd.Series(y_test).value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv4YilvOzS5z"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the image\n",
        "image = cv2.imread(\"/content/drive/MyDrive/8.jpg\", flags=0)\n",
        "\n",
        "# Simple Thresholding\n",
        "ret, thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "ret, thresh2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "ret, thresh3 = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
        "ret, thresh4 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
        "ret, thresh5 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\n",
        "\n",
        "# Titles for each image\n",
        "titles = ['Original Image', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']\n",
        "\n",
        "# List of thresholded images\n",
        "images = [image, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
        "\n",
        "# Plotting the images\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(images[i], cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(titles[i])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjWQRRh43Mnj"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imread(\"/content/drive/MyDrive/ben10.png\")\n",
        "\n",
        "# Check if the image is loaded successfully\n",
        "if img is None:\n",
        "    print(\"Error: Could not read the image.\")\n",
        "else:\n",
        "    # Scaling\n",
        "    height, width = img.shape[:2]  # Get the height and width\n",
        "    res = cv2.resize(img, (2 * width, 2 * height), interpolation=cv2.INTER_NEAREST)  # Resize the image\n",
        "    print(\"Scaled image shape:\", res.shape)  # Print the shape of the resized image\n",
        "    plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display\n",
        "    plt.title('Scaled Image')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Transformation - Translation\n",
        "    M_translation = np.float32([[1, 0, 50], [0, 1, 40]])  # Translation matrix\n",
        "    dst_translation = cv2.warpAffine(img, M_translation, (width, height))  # Apply translation\n",
        "    plt.imshow(cv2.cvtColor(dst_translation, cv2.COLOR_BGR2RGB))  # Convert to RGB\n",
        "    plt.title('Translated Image')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Rotation\n",
        "    M_rotation = cv2.getRotationMatrix2D((width / 2, height / 2), 50, 1)  # Rotation matrix\n",
        "    dst_rotation = cv2.warpAffine(img, M_rotation, (width, height))  # Apply rotation\n",
        "    plt.imshow(cv2.cvtColor(dst_rotation, cv2.COLOR_BGR2RGB))  # Convert to RGB\n",
        "    plt.title('Rotated Image')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Morphological erosion \"shrinks the boundaries\"\n",
        "    kernel = np.ones((2, 2), np.uint8)  # Define the kernel\n",
        "    erosion = cv2.erode(img, kernel, iterations=1)  # Apply erosion\n",
        "    plt.imshow(cv2.cvtColor(erosion, cv2.COLOR_BGR2RGB))  # Convert to RGB\n",
        "    plt.title('Erosion')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Dilation \"expands the boundaries\"\n",
        "    dilation = cv2.dilate(img, kernel, iterations=1)  # Apply dilation\n",
        "    plt.imshow(cv2.cvtColor(dilation, cv2.COLOR_BGR2RGB))  # Convert to RGB\n",
        "    plt.title('Dilation')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Opening (erosion followed by dilation)\n",
        "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)  # Apply opening\n",
        "    plt.imshow(cv2.cvtColor(opening, cv2.COLOR_BGR2RGB))  # Convert to RGB\n",
        "    plt.title('Opening')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Closing (dilation followed by erosion)\n",
        "    closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)  # Apply closing\n",
        "    plt.imshow(cv2.cvtColor(closing, cv2.COLOR_BGR2RGB))  # Convert to RGB\n",
        "    plt.title('Closing')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vskbc1t36LJx"
      },
      "outputs": [],
      "source": [
        "# Example 5: Image Gradients and Edge Detection\n",
        "\n",
        "# Importing the libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Loading the Image\n",
        "image = cv2.imread(\"/content/drive/MyDrive/8.jpg\")\n",
        "if image is None:\n",
        "    print(\"Error: Could not read the image.\")\n",
        "else:\n",
        "    # Convert to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Display the grayscale image\n",
        "    plt.imshow(gray_image, cmap='gray')\n",
        "    plt.title('Grayscale Image')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Laplacian\n",
        "    lap = cv2.Laplacian(gray_image, cv2.CV_64F)\n",
        "    lap = np.uint8(np.absolute(lap))\n",
        "    plt.imshow(lap, cmap='gray')\n",
        "    plt.title('Laplacian Edge Detection')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Sobel\n",
        "    sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0)  # Sobel in x direction\n",
        "    sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1)  # Sobel in y direction\n",
        "    sobel_x = np.uint8(np.absolute(sobel_x))\n",
        "    sobel_y = np.uint8(np.absolute(sobel_y))\n",
        "    sobel_combined = cv2.bitwise_or(sobel_x, sobel_y)\n",
        "\n",
        "    # Display Sobel combined image\n",
        "    plt.imshow(sobel_combined, cmap='gray')\n",
        "    plt.title('Sobel Edge Detection')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Canny\n",
        "    edges = cv2.Canny(gray_image, 70, 170)\n",
        "\n",
        "    # Display Canny edges\n",
        "    plt.imshow(edges, cmap='gray')\n",
        "    plt.title('Canny Edge Detection')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E9rKI2U7VfY"
      },
      "outputs": [],
      "source": [
        "# Example 6: Harris Corner Detection\n",
        "\n",
        "# Importing the libraries\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Loading the image\n",
        "img = cv2.imread('/content/drive/MyDrive/8.jpg')\n",
        "\n",
        "# Converting the image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Harris Corner Detection\n",
        "corners = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
        "\n",
        "# Marking the corners on the original image\n",
        "img[corners > 0.01 * corners.max()] = [0, 255, 0]  # Change color to green\n",
        "\n",
        "# Displaying the image with corners\n",
        "cv2_imshow(img)\n",
        "plt.title('Harris Corner Detection')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk_NBn_L8akU"
      },
      "outputs": [],
      "source": [
        "# Example 7: Image Contours\n",
        "\n",
        "# Importing the libraries\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Loading the image\n",
        "image = cv2.imread(\"/content/drive/MyDrive/8.jpg\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "# Converting the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)\n",
        "\n",
        "# Blurring the image to reduce noise\n",
        "blurred = cv2.GaussianBlur(gray, (11, 11), 0)\n",
        "cv2_imshow(blurred)\n",
        "\n",
        "# Detecting edges using Canny\n",
        "edges = cv2.Canny(blurred, 30, 80)\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Canny Edges')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Finding contours\n",
        "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Creating a copy of the original image to draw contours\n",
        "contour_image = image.copy()\n",
        "cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "# Displaying the image with contours\n",
        "cv2_imshow(contour_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 8: Face Detection using Haar Cascade\n",
        "\n",
        "# Importing the libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Importing the xml file for face detection\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_frontalface_default.xml')  # Make sure to use the correct path\n",
        "\n",
        "# Importing the image\n",
        "image = cv2.imread(\"/content/drive/MyDrive/MCU.jpg\")  # Change to your image file name or path\n",
        "# image = cv2.imread(\"/content/friends.jpg\")  # Uncomment to use a different image\n",
        "\n",
        "# Converting to grayscale for face detection\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Face detection\n",
        "face_rects = face_cascade.detectMultiScale(gray_image, scaleFactor=1.2, minNeighbors=5)\n",
        "\n",
        "# Drawing rectangles around detected faces\n",
        "for (x, y, w, h) in face_rects:\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Corrected the rectangle coordinates\n",
        "\n",
        "# Display the output image with detected faces\n",
        "cv2_imshow(image)\n"
      ],
      "metadata": {
        "id": "FXGqDZlT-SAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing necessary libraries\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Define some patterns and responses\n",
        "patterns = [\n",
        "    (r'hello|hey|hi', ['Hello!', 'Hi there!', 'Hey!']),\n",
        "    (r'what is your name\\??', ['You can call me ChatGPT.', 'I go by the name ChatGPT.']),\n",
        "    (r'how are you\\??', [\"I'm good, thank you!\", \"I'm doing well, thanks for asking.\"]),\n",
        "    # Add more patterns and responses here\n",
        "]\n",
        "\n",
        "# Create a chatbot\n",
        "chatbot = Chat(patterns, reflections)\n",
        "\n",
        "# Start the conversation\n",
        "print(\"Hello! I'm ChatGPT. How can I help you today?\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"ChatGPT: Goodbye!\")\n",
        "        break\n",
        "    response = chatbot.respond(user_input)\n",
        "    print(\"ChatGPT:\", response)\n"
      ],
      "metadata": {
        "id": "Sl9GEnJtApSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}